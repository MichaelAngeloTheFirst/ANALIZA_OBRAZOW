{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as img\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 267 files belonging to 3 classes.\n",
      "Using 214 files for training.\n",
      "Found 267 files belonging to 3 classes.\n",
      "Using 53 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "height, width = (256,256)\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    seed=100,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size = (height, width), \n",
    "    batch_size = batch_size,\n",
    "    subset = 'training',\n",
    "    validation_split=0.2,\n",
    "    shuffle = True,\n",
    "    color_mode=\"rgb\",\n",
    "    class_names=(\"Deinopis_Spider\",\"Red_Knee_Tarantula\", \"Peacock_Spider\")\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    seed=100,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size = (height, width), \n",
    "    batch_size = batch_size,\n",
    "    subset = 'validation',\n",
    "    validation_split=0.2,\n",
    "    shuffle = True,\n",
    "    color_mode=\"rgb\",\n",
    "    class_names=(\"Deinopis_Spider\",\"Red_Knee_Tarantula\", \"Peacock_Spider\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "initializers = {\n",
    "\n",
    "}\n",
    "model.add(\n",
    "    keras.layers.RandomFlip(\"horizontal_and_vertical\") )\n",
    "model.add(\n",
    "    keras.layers.RandomRotation(0.2)\n",
    ")\n",
    "model.add(\n",
    "    keras.layers.Rescaling(1/127.0, offset=-1)\n",
    ")\n",
    "model.add( \n",
    "    keras.layers.Conv2D(\n",
    "        24, 5, input_shape=(256,256,3), \n",
    "        activation='relu', \n",
    "    )\n",
    ")\n",
    "model.add( keras.layers.MaxPooling2D(2) )\n",
    "model.add( \n",
    "    keras.layers.Conv2D(\n",
    "        48, 5, activation='relu', \n",
    "    )\n",
    ")\n",
    "model.add( keras.layers.MaxPooling2D(2) )\n",
    "model.add( \n",
    "    keras.layers.Conv2D(\n",
    "        96, 5, activation='relu', \n",
    "    )\n",
    ")\n",
    "model.add( keras.layers.Flatten() )\n",
    "model.add( keras.layers.Dropout(0.9) )\n",
    "\n",
    "model.add( keras.layers.Dense(\n",
    "    3, activation='softmax',\n",
    "    )\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = tuple(zip(*train_dataset))\n",
    "# images = np.array(images)\n",
    "# labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "7/7 [==============================] - 10s 1s/step - loss: 2.0936 - acc: 0.5047 - val_loss: 0.8933 - val_acc: 0.6038\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.7623 - acc: 0.6636 - val_loss: 0.9305 - val_acc: 0.6038\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6387 - acc: 0.7617 - val_loss: 0.8540 - val_acc: 0.6226\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.5733 - acc: 0.7757 - val_loss: 0.9717 - val_acc: 0.6415\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.4935 - acc: 0.8318 - val_loss: 0.7979 - val_acc: 0.7547\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.4370 - acc: 0.8271 - val_loss: 1.1582 - val_acc: 0.6415\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.5161 - acc: 0.7897 - val_loss: 0.8324 - val_acc: 0.6981\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.4149 - acc: 0.8645 - val_loss: 0.8738 - val_acc: 0.7170\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.4943 - acc: 0.8318 - val_loss: 0.8236 - val_acc: 0.7358\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.3738 - acc: 0.8645 - val_loss: 0.8188 - val_acc: 0.7170\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.3604 - acc: 0.8692 - val_loss: 0.7297 - val_acc: 0.7170\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2721 - acc: 0.8972 - val_loss: 0.8703 - val_acc: 0.7736\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2823 - acc: 0.9112 - val_loss: 0.7889 - val_acc: 0.8113\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.3036 - acc: 0.9019 - val_loss: 0.7156 - val_acc: 0.7736\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.3193 - acc: 0.9065 - val_loss: 0.7392 - val_acc: 0.6981\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.3544 - acc: 0.8785 - val_loss: 0.8385 - val_acc: 0.7358\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.3022 - acc: 0.8692 - val_loss: 0.5516 - val_acc: 0.8491\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2954 - acc: 0.8925 - val_loss: 0.6447 - val_acc: 0.8113\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2342 - acc: 0.8925 - val_loss: 0.6675 - val_acc: 0.7925\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2538 - acc: 0.8832 - val_loss: 0.4595 - val_acc: 0.8491\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=10,\n",
    "    epochs=20,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[0.01999357 0.7863108  0.19369565]]\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.4595 - acc: 0.8491\n",
      "0.45954883098602295 0.849056601524353\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# type(plt.imread(\"Red_Knee_Tarantula/red.069.jpg\"))\n",
    "temp = np.empty((1,256,256,3))\n",
    "temp[0]=cv2.resize(plt.imread(\"train/Brach.jpg\"),(256,256),interpolation= cv2.INTER_NEAREST)\n",
    "\n",
    "# plt.imshow(temp[0][:,:,::-1])\n",
    "print(model.predict([temp]))\n",
    "\n",
    "val_los , val_acc = model.evaluate(val_dataset)\n",
    "print(val_los, val_acc)\n",
    "\n",
    "# loss: 0.1834 - acc: 0.9299 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28b06ec166af8c83e5882731fef908354c2d57d9b46df793dcdb4efcedb4ca54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
