{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as img\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 267 files belonging to 3 classes.\n",
      "Using 214 files for training.\n",
      "Found 267 files belonging to 3 classes.\n",
      "Using 53 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "height, width = (256,256)\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    seed=100,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size = (height, width), \n",
    "    batch_size = batch_size,\n",
    "    subset = 'training',\n",
    "    validation_split=0.2,\n",
    "    shuffle = True,\n",
    "    color_mode=\"rgb\",\n",
    "    class_names=(\"Deinopis_Spider\",\"Red_Knee_Tarantula\", \"Peacock_Spider\")\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    seed=100,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size = (height, width), \n",
    "    batch_size = batch_size,\n",
    "    subset = 'validation',\n",
    "    validation_split=0.2,\n",
    "    shuffle = True,\n",
    "    color_mode=\"rgb\",\n",
    "    class_names=(\"Deinopis_Spider\",\"Red_Knee_Tarantula\", \"Peacock_Spider\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "initializers = {\n",
    "\n",
    "}\n",
    "model.add(\n",
    "    keras.layers.RandomFlip(\"horizontal_and_vertical\") )\n",
    "model.add(\n",
    "    keras.layers.RandomRotation(0.2)\n",
    ")\n",
    "model.add(\n",
    "    keras.layers.Rescaling(1/127.0, offset=-1)\n",
    ")\n",
    "model.add( \n",
    "    keras.layers.Conv2D(\n",
    "        24, 5, input_shape=(256,256,3), \n",
    "        activation='relu', \n",
    "    )\n",
    ")\n",
    "model.add( keras.layers.MaxPooling2D(2) )\n",
    "model.add( \n",
    "    keras.layers.Conv2D(\n",
    "        48, 5, activation='relu', \n",
    "    )\n",
    ")\n",
    "model.add( keras.layers.MaxPooling2D(2) )\n",
    "model.add( \n",
    "    keras.layers.Conv2D(\n",
    "        96, 5, activation='relu', \n",
    "    )\n",
    ")\n",
    "model.add( keras.layers.Flatten() )\n",
    "model.add( keras.layers.Dropout(0.9) )\n",
    "\n",
    "model.add( keras.layers.Dense(\n",
    "    3, activation='softmax',\n",
    "    )\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "7/7 [==============================] - 11s 1s/step - loss: 2.1343 - acc: 0.5140 - val_loss: 0.8907 - val_acc: 0.5283\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.7852 - acc: 0.6262 - val_loss: 0.8925 - val_acc: 0.5283\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6459 - acc: 0.7150 - val_loss: 1.0266 - val_acc: 0.6604\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6026 - acc: 0.7570 - val_loss: 0.6312 - val_acc: 0.7736\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.4987 - acc: 0.8084 - val_loss: 0.8610 - val_acc: 0.7358\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.4438 - acc: 0.8224 - val_loss: 0.6619 - val_acc: 0.8302\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.3847 - acc: 0.8598 - val_loss: 0.8208 - val_acc: 0.7547\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.3997 - acc: 0.8224 - val_loss: 0.5309 - val_acc: 0.8868\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.3412 - acc: 0.8645 - val_loss: 0.6794 - val_acc: 0.8302\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.3141 - acc: 0.8785 - val_loss: 0.4136 - val_acc: 0.9057\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2990 - acc: 0.8879 - val_loss: 0.4997 - val_acc: 0.9057\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2456 - acc: 0.9065 - val_loss: 0.3584 - val_acc: 0.9057\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2424 - acc: 0.8925 - val_loss: 0.5185 - val_acc: 0.8491\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2212 - acc: 0.9299 - val_loss: 0.4804 - val_acc: 0.9245\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2020 - acc: 0.9346 - val_loss: 0.3896 - val_acc: 0.9057\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.2187 - acc: 0.9112 - val_loss: 0.4020 - val_acc: 0.9245\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1896 - acc: 0.9252 - val_loss: 0.3048 - val_acc: 0.9245\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1904 - acc: 0.9159 - val_loss: 0.4266 - val_acc: 0.9057\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.1830 - acc: 0.9346 - val_loss: 0.3236 - val_acc: 0.9245\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.1433 - acc: 0.9439 - val_loss: 0.3281 - val_acc: 0.9245\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data = val_dataset,\n",
    "    workers=10,\n",
    "    epochs=20,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None, 256, 256, 3) dtype=float32>,). Consider rewriting this model with the Functional API.\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "[[9.7243494e-01 8.4907957e-04 2.6715985e-02]]\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.3281 - acc: 0.9245\n",
      "0.3280733823776245 0.9245283007621765\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# type(plt.imread(\"Red_Knee_Tarantula/red.069.jpg\"))\n",
    "temp = np.empty((1,256,256,3))\n",
    "temp[0]=cv2.resize(plt.imread(\"train/kaczki.jpg\"),(256,256),interpolation= cv2.INTER_NEAREST)\n",
    "\n",
    "# plt.imshow(temp[0][:,:,::-1])\n",
    "print(model.predict([temp]))\n",
    "\n",
    "val_los , val_acc = model.evaluate(val_dataset)\n",
    "print(val_los, val_acc)\n",
    "\n",
    "# loss: 0.1834 - acc: 0.9299 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28b06ec166af8c83e5882731fef908354c2d57d9b46df793dcdb4efcedb4ca54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
